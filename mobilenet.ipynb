{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os, shutil\nimport tensorflow as tf\n#Importing libraries to interact with Operating system\n","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_dir = os.path.join('../input/vggwallcrackuncrackdataset/train')\nvalidation_dir = os.path.join('../input/vggwallcrackuncrackdataset/validation')\ntest_dir = os.path.join('../input/vggwallcrackuncrackdataset/test')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_crack_dir = os.path.join('../input/vggwallcrackuncrackdataset/train/crack')\ntrain_no_crack_dir = os.path.join('../input/vggwallcrackuncrackdataset/train/non crack')\nvalidation_crack_dir = os.path.join('../input/vggwallcrackuncrackdataset/validation/crack')\nvalidation_no_crack_dir = os.path.join('../input/vggwallcrackuncrackdataset/validation/non crack')\ntest_crack_dir = os.path.join('../input/vggwallcrackuncrackdataset/test/crack')\ntest_no_crack_dir = os.path.join('../input/vggwallcrackuncrackdataset/test/non crack')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('total training crack  images:', len(os.listdir(train_crack_dir)))\nprint('total training no crack images:', len(os.listdir(train_no_crack_dir)))\n\n\nprint('total validation crack images:', len(os.listdir(validation_crack_dir)))\nprint('total validation no crack images:', len(os.listdir(validation_no_crack_dir)))\n\nprint('total test crack images:', len(os.listdir(test_crack_dir)))\nprint('total test no crack images:', len(os.listdir(test_no_crack_dir)))","execution_count":4,"outputs":[{"output_type":"stream","text":"total training crack  images: 1250\ntotal training no crack images: 1250\ntotal validation crack images: 500\ntotal validation no crack images: 500\ntotal test crack images: 500\ntotal test no crack images: 500\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras import models\n#Importing keras for preprocessing the data to feed to the network","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(227, 227),\n    batch_size=20,\n    class_mode='categorical')\nvalidation_generator = test_datagen.flow_from_directory(validation_dir,\n                                                        target_size=(227, 227),\n                                                        batch_size=1,\n                                                        class_mode='categorical')\n#Scaling the pixel values of images between 0 and 1\n#taregt_size is The dimensions to which all images found will be resized\n#batch_size denotes the subset size of training sample\n#class_mode: classify between different categories like crack and no crack","execution_count":6,"outputs":[{"output_type":"stream","text":"Found 2500 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data_batch, labels_batch in train_generator:\n  print('data batch shape:', data_batch.shape)\n  print('labels batch shape:', labels_batch.shape)\n  break\n#Defining data per batch for training ","execution_count":7,"outputs":[{"output_type":"stream","text":"data batch shape: (20, 227, 227, 3)\nlabels batch shape: (20, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SHAPE = (224, 224, 3)\nbase_model = tf.keras.applications.MobileNetV2(\n    input_shape=IMG_SHAPE,\n    alpha=1.0,\n    include_top=False,\n    weights=\"imagenet\",\n    \n    \n    \n    classifier_activation=\"softmax\",\n    \n)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_batch = base_model(data_batch)\nprint(feature_batch.shape)\n#Dimension metrics 20x8x8","execution_count":9,"outputs":[{"output_type":"stream","text":"(20, 7, 7, 1280)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = False","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.summary()","execution_count":11,"outputs":[{"output_type":"stream","text":"Model: \"mobilenetv2_1.00_224\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n__________________________________________________________________________________________________\nConv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n__________________________________________________________________________________________________\nConv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n__________________________________________________________________________________________________\nbn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n__________________________________________________________________________________________________\nConv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n__________________________________________________________________________________________________\nexpanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n__________________________________________________________________________________________________\nexpanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n__________________________________________________________________________________________________\nexpanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n__________________________________________________________________________________________________\nexpanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n__________________________________________________________________________________________________\nexpanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n__________________________________________________________________________________________________\nblock_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n__________________________________________________________________________________________________\nblock_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n__________________________________________________________________________________________________\nblock_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n__________________________________________________________________________________________________\nblock_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n__________________________________________________________________________________________________\nblock_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n__________________________________________________________________________________________________\nblock_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n__________________________________________________________________________________________________\nblock_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n                                                                 block_2_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n__________________________________________________________________________________________________\nblock_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n__________________________________________________________________________________________________\nblock_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n__________________________________________________________________________________________________\nblock_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n__________________________________________________________________________________________________\nblock_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n__________________________________________________________________________________________________\nblock_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n__________________________________________________________________________________________________\nblock_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n                                                                 block_4_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n__________________________________________________________________________________________________\nblock_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n__________________________________________________________________________________________________\nblock_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n__________________________________________________________________________________________________\nblock_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n                                                                 block_5_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n__________________________________________________________________________________________________\nblock_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n__________________________________________________________________________________________________\nblock_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n__________________________________________________________________________________________________\nblock_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n__________________________________________________________________________________________________\nblock_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n__________________________________________________________________________________________________\nblock_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n__________________________________________________________________________________________________\nblock_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n                                                                 block_7_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n__________________________________________________________________________________________________\nblock_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n__________________________________________________________________________________________________\nblock_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n__________________________________________________________________________________________________\nblock_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n                                                                 block_8_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n__________________________________________________________________________________________________\nblock_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n__________________________________________________________________________________________________\nblock_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n__________________________________________________________________________________________________\nblock_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n__________________________________________________________________________________________________\nblock_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n__________________________________________________________________________________________________\nblock_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n__________________________________________________________________________________________________\nblock_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n__________________________________________________________________________________________________\nblock_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n__________________________________________________________________________________________________\nblock_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n                                                                 block_9_project_BN[0][0]         \n__________________________________________________________________________________________________\nblock_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n__________________________________________________________________________________________________\nblock_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n__________________________________________________________________________________________________\nblock_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n__________________________________________________________________________________________________\nblock_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n__________________________________________________________________________________________________\nblock_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n__________________________________________________________________________________________________\nblock_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n                                                                 block_11_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n__________________________________________________________________________________________________\nblock_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n__________________________________________________________________________________________________\nblock_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n__________________________________________________________________________________________________\nblock_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n                                                                 block_12_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n__________________________________________________________________________________________________\nblock_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n__________________________________________________________________________________________________\nblock_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n__________________________________________________________________________________________________\nblock_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n__________________________________________________________________________________________________\nblock_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n__________________________________________________________________________________________________\nblock_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n                                                                 block_14_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n__________________________________________________________________________________________________\nblock_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n__________________________________________________________________________________________________\nblock_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n__________________________________________________________________________________________________\nblock_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n                                                                 block_15_project_BN[0][0]        \n__________________________________________________________________________________________________\nblock_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n__________________________________________________________________________________________________\nblock_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n__________________________________________________________________________________________________\nblock_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n__________________________________________________________________________________________________\nblock_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n__________________________________________________________________________________________________\nblock_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n__________________________________________________________________________________________________\nblock_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n__________________________________________________________________________________________________\nblock_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n__________________________________________________________________________________________________\nConv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n__________________________________________________________________________________________________\nConv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n__________________________________________________________________________________________________\nout_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n==================================================================================================\nTotal params: 2,257,984\nTrainable params: 0\nNon-trainable params: 2,257,984\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)","execution_count":12,"outputs":[{"output_type":"stream","text":"(20, 1280)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_layer = tf.keras.layers.Dense(2)\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","execution_count":13,"outputs":[{"output_type":"stream","text":"(20, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n  base_model,\n  global_average_layer,\n  prediction_layer\n])","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd = tf.keras.optimizers.SGD(lr=1e-6, decay=1e-6, momentum=1, nesterov=True)\nmodel.compile(optimizer=sgd,loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":16,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmobilenetv2_1.00_224 (Model) (None, 7, 7, 1280)        2257984   \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 1280)              0         \n_________________________________________________________________\ndense (Dense)                (None, 2)                 2562      \n=================================================================\nTotal params: 2,260,546\nTrainable params: 2,562\nNon-trainable params: 2,257,984\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(model.trainable_variables)","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"2"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_epochs = 40\nvalidation_steps=10\n\nloss0,accuracy0 = model.evaluate(validation_generator, steps = validation_steps)","execution_count":18,"outputs":[{"output_type":"stream","text":"10/10 [==============================] - 0s 6ms/step - loss: 0.8243 - accuracy: 0.5000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"initial loss: {:.2f}\".format(loss0))\nprint(\"initial accuracy: {:.2f}\".format(accuracy0))","execution_count":19,"outputs":[{"output_type":"stream","text":"initial loss: 0.82\ninitial accuracy: 0.50\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(227, 227),\n    batch_size=20,\n    class_mode='binary')","execution_count":20,"outputs":[{"output_type":"stream","text":"Found 2500 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X,Y = train_generator.next()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.model_selection import StratifiedKFold\nimport numpy\n# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n# load pima indians dataset\n\n# split into input (X) and output (Y) variables\nX,Y = train_generator.next()\n# define 10-fold cross validation test harness\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\ncvscores = []\nfor train, test in kfold.split(X, Y):\n    base_model = tf.keras.applications.MobileNetV2(\n    input_shape=IMG_SHAPE,\n    alpha=1.0,\n    include_top=False,\n    weights=\"imagenet\",\n    \n    \n    \n    classifier_activation=\"softmax\",\n    \n    )\n    base_model.trainable = False\n    feature_batch = base_model(data_batch)\n    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n    feature_batch_average = global_average_layer(feature_batch)\n    prediction_layer = tf.keras.layers.Dense(2)\n    prediction_batch = prediction_layer(feature_batch_average)\n    \n  \n    model = tf.keras.Sequential([base_model,global_average_layer,prediction_layer])\n\n        \n    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n    \n    model.fit(X[train], Y[train], epochs=40, batch_size=2500, verbose=0)\n    \n    scores = model.evaluate(X[test], Y[test], verbose=0)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)\nprint(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_generator,\n                    epochs=initial_epochs,\n                    validation_data=validation_generator)\n#Fitting the model in a CNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\naccuracy = history.history['accuracy']\nval_accuracy= history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(accuracy, label='Training Accuracy')\nplt.plot(val_accuracy, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()\n#Plotting graphs b/w different parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntest_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=(200, 200),\n        color_mode=\"rgb\",\n        shuffle = False,\n        class_mode='categorical',\n        batch_size=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport numpy\ntest_steps_per_epoch = numpy.math.ceil(test_generator.samples / test_generator.batch_size)\npredictions = model.predict_generator(test_generator, steps=1000)\n\npredicted_classes = numpy.argmax(predictions, axis=1)\ntrue_classes = test_generator.classes\nclass_labels = list(test_generator.class_indices.keys())\nreport = classification_report(true_classes, predicted_classes, target_names=class_labels)\nprint(report)   \n\ncm=confusion_matrix(true_classes,predicted_classes)\nprint(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(227, 227),\n    batch_size=2500,\n    class_mode='categorical')\nX,Y = train_generator.next()\n","execution_count":21,"outputs":[{"output_type":"stream","text":"Found 2500 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.losses import sparse_categorical_crossentropy\n\nfrom sklearn.model_selection import KFold\nimport numpy as np\n\n# Model configuration\nbatch_size = 50\nimg_width, img_height, img_num_channels = 227, 227, 3\nloss_function = sparse_categorical_crossentropy\nno_classes = 2\nno_epochs = 25\n\nverbosity = 1\nnum_folds = 10\n\n\n(input_train, target_train)= train_generator.next()\n(input_test, target_test) =  validation_generator.next()\n\n\ninput_shape = (img_width, img_height, img_num_channels)\n\n\ninput_train = input_train.astype('float32')\ninput_test = input_test.astype('float32')\n\n# Normalize data\n\n\n# Define per-fold score containers\nacc_per_fold = []\nloss_per_fold = []\n\n# Merge inputs and targets\ninputs = input_train\ntargets = target_train\n\n# Define the K-fold Cross Validator\nkfold = KFold(n_splits=num_folds, shuffle=True)\n\n# K-fold Cross Validation model evaluation\nfold_no = 1","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfor train, test in kfold.split(inputs, targets):\n    \n    model = model\n\n  # Define the model architecture\n\n\n  # Compile the model\n    model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['accuracy'])\n\n\n  # Generate a print\n    print('------------------------------------------------------------------------')\n    print(f'Training for fold {fold_no} ...')\n\n  # Fit data to model\n    history = model.fit(inputs[train], targets[train],batch_size=batch_size,epochs=no_epochs,verbose=verbosity)\n\n  # Generate generalization metrics\n    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n    acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n\n  # Increase fold number\n    fold_no = fold_no + 1\n\n# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n    \n    \n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","execution_count":23,"outputs":[{"output_type":"stream","text":"------------------------------------------------------------------------\nTraining for fold 1 ...\nEpoch 1/25\n45/45 [==============================] - 2s 45ms/step - loss: 4.4786 - accuracy: 0.4458\nEpoch 2/25\n45/45 [==============================] - 2s 48ms/step - loss: 2.5253 - accuracy: 0.6582\nEpoch 3/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.8858 - accuracy: 0.9093\nEpoch 4/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.4210 - accuracy: 0.9782\nEpoch 5/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.4008 - accuracy: 0.9916\nEpoch 6/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.2581 - accuracy: 0.9933\nEpoch 7/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.1726 - accuracy: 0.9951\nEpoch 8/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.1017 - accuracy: 0.9947\nEpoch 9/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0571 - accuracy: 0.9960\nEpoch 10/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0366 - accuracy: 0.9964\nEpoch 11/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0374 - accuracy: 0.9969\nEpoch 12/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0439 - accuracy: 0.9969\nEpoch 13/25\n45/45 [==============================] - 2s 53ms/step - loss: 0.0506 - accuracy: 0.9973\nEpoch 14/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0548 - accuracy: 0.9969\nEpoch 15/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0675 - accuracy: 0.9964\nEpoch 16/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0713 - accuracy: 0.9969\nEpoch 17/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0776 - accuracy: 0.9969\nEpoch 18/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0815 - accuracy: 0.9969\nEpoch 19/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0885 - accuracy: 0.9969\nEpoch 20/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0910 - accuracy: 0.9969\nEpoch 21/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0910 - accuracy: 0.9969\nEpoch 22/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0940 - accuracy: 0.9964\nEpoch 23/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0943 - accuracy: 0.9964\nEpoch 24/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0946 - accuracy: 0.9964\nEpoch 25/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0955 - accuracy: 0.9960\nScore for fold 1: loss of 0.2443392276763916; accuracy of 98.7999975681305%\n------------------------------------------------------------------------\nTraining for fold 2 ...\nEpoch 1/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.1118 - accuracy: 0.9956\nEpoch 2/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.1111 - accuracy: 0.9956\nEpoch 3/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.1106 - accuracy: 0.9956\nEpoch 4/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.1103 - accuracy: 0.9956\nEpoch 5/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.1100 - accuracy: 0.9956\nEpoch 6/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.1097 - accuracy: 0.9956\nEpoch 7/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.1095 - accuracy: 0.9956\nEpoch 8/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.1092 - accuracy: 0.9956\nEpoch 9/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.1090 - accuracy: 0.9956\nEpoch 10/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.1065 - accuracy: 0.9956\nEpoch 11/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.1029 - accuracy: 0.9956\nEpoch 12/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.1026 - accuracy: 0.9956\nEpoch 13/25\n45/45 [==============================] - 2s 53ms/step - loss: 0.1024 - accuracy: 0.9956\nEpoch 14/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.1023 - accuracy: 0.9956\nEpoch 15/25\n45/45 [==============================] - 2s 50ms/step - loss: 0.0977 - accuracy: 0.9956\nEpoch 16/25\n45/45 [==============================] - 2s 50ms/step - loss: 0.0964 - accuracy: 0.9956\nEpoch 17/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0936 - accuracy: 0.9956\nEpoch 18/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0900 - accuracy: 0.9956\nEpoch 19/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0893 - accuracy: 0.9956\nEpoch 20/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0891 - accuracy: 0.9956\nEpoch 21/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0888 - accuracy: 0.9956\nEpoch 22/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0887 - accuracy: 0.9956\nEpoch 23/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0887 - accuracy: 0.9956\nEpoch 24/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0888 - accuracy: 0.9956\nEpoch 25/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0889 - accuracy: 0.9956\nScore for fold 2: loss of 0.06134837493300438; accuracy of 99.59999918937683%\n------------------------------------------------------------------------\nTraining for fold 3 ...\nEpoch 1/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0822 - accuracy: 0.9960\nEpoch 2/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0824 - accuracy: 0.9960\nEpoch 3/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0795 - accuracy: 0.9960\nEpoch 4/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0792 - accuracy: 0.9960\nEpoch 5/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0791 - accuracy: 0.9960\nEpoch 6/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0791 - accuracy: 0.9960\nEpoch 7/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0792 - accuracy: 0.9960\nEpoch 8/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0819 - accuracy: 0.9964\nEpoch 9/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0764 - accuracy: 0.9964\nEpoch 10/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0760 - accuracy: 0.9964\nEpoch 11/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0758 - accuracy: 0.9964\nEpoch 12/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0756 - accuracy: 0.9964\nEpoch 13/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0756 - accuracy: 0.9964\nEpoch 14/25\n45/45 [==============================] - 2s 54ms/step - loss: 0.0731 - accuracy: 0.9964\nEpoch 15/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0729 - accuracy: 0.9964\nEpoch 16/25\n45/45 [==============================] - 2s 50ms/step - loss: 0.0703 - accuracy: 0.9964\nEpoch 17/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0691 - accuracy: 0.9964\nEpoch 18/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0660 - accuracy: 0.9964\nEpoch 19/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0655 - accuracy: 0.9964\nEpoch 20/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0653 - accuracy: 0.9964\nEpoch 21/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0622 - accuracy: 0.9964\nEpoch 22/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0617 - accuracy: 0.9964\nEpoch 23/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0616 - accuracy: 0.9964\nEpoch 24/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0614 - accuracy: 0.9964\nEpoch 25/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0614 - accuracy: 0.9964\nScore for fold 3: loss of 0.12234532088041306; accuracy of 99.19999837875366%\n------------------------------------------------------------------------\nTraining for fold 4 ...\nEpoch 1/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0715 - accuracy: 0.9956\nEpoch 2/25\n","name":"stdout"},{"output_type":"stream","text":"45/45 [==============================] - 2s 48ms/step - loss: 0.0689 - accuracy: 0.9956\nEpoch 3/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0684 - accuracy: 0.9956\nEpoch 4/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0684 - accuracy: 0.9956\nEpoch 5/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0684 - accuracy: 0.9956\nEpoch 6/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0684 - accuracy: 0.9956\nEpoch 7/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0684 - accuracy: 0.9956\nEpoch 8/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0684 - accuracy: 0.9956\nEpoch 9/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0684 - accuracy: 0.9956\nEpoch 10/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0685 - accuracy: 0.9956\nEpoch 11/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0686 - accuracy: 0.9956\nEpoch 12/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0688 - accuracy: 0.9956\nEpoch 13/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0689 - accuracy: 0.9956\nEpoch 14/25\n45/45 [==============================] - 2s 50ms/step - loss: 0.0692 - accuracy: 0.9956\nEpoch 15/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0719 - accuracy: 0.9956\nEpoch 16/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0720 - accuracy: 0.9956\nEpoch 17/25\n45/45 [==============================] - 2s 50ms/step - loss: 0.0721 - accuracy: 0.9956\nEpoch 18/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0722 - accuracy: 0.9956\nEpoch 19/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0723 - accuracy: 0.9956\nEpoch 20/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0724 - accuracy: 0.9956\nEpoch 21/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0723 - accuracy: 0.9956\nEpoch 22/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0721 - accuracy: 0.9956\nEpoch 23/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0721 - accuracy: 0.9956\nEpoch 24/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0690 - accuracy: 0.9956\nEpoch 25/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0688 - accuracy: 0.9956\nScore for fold 4: loss of 0.0012238811468705535; accuracy of 100.0%\n------------------------------------------------------------------------\nTraining for fold 5 ...\nEpoch 1/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0689 - accuracy: 0.9956\nEpoch 2/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0689 - accuracy: 0.9956\nEpoch 3/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0689 - accuracy: 0.9956\nEpoch 4/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0689 - accuracy: 0.9956\nEpoch 5/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0695 - accuracy: 0.9956\nEpoch 6/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0718 - accuracy: 0.9956\nEpoch 7/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0717 - accuracy: 0.9951\nEpoch 8/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0717 - accuracy: 0.9951\nEpoch 9/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0717 - accuracy: 0.9951\nEpoch 10/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0691 - accuracy: 0.9951\nEpoch 11/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0689 - accuracy: 0.9951\nEpoch 12/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0687 - accuracy: 0.9951\nEpoch 13/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0686 - accuracy: 0.9951\nEpoch 14/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0685 - accuracy: 0.9951\nEpoch 15/25\n45/45 [==============================] - 2s 51ms/step - loss: 0.0685 - accuracy: 0.9951\nEpoch 16/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0684 - accuracy: 0.9951\nEpoch 17/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0684 - accuracy: 0.9951\nEpoch 18/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0684 - accuracy: 0.9951\nEpoch 19/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0684 - accuracy: 0.9951\nEpoch 20/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0684 - accuracy: 0.9951\nEpoch 21/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0684 - accuracy: 0.9951\nEpoch 22/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0683 - accuracy: 0.9951\nEpoch 23/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0683 - accuracy: 0.9951\nEpoch 24/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0683 - accuracy: 0.9951\nEpoch 25/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0683 - accuracy: 0.9951\nScore for fold 5: loss of 0.0; accuracy of 100.0%\n------------------------------------------------------------------------\nTraining for fold 6 ...\nEpoch 1/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0581 - accuracy: 0.9956\nEpoch 2/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0581 - accuracy: 0.9956\nEpoch 3/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0581 - accuracy: 0.9956\nEpoch 4/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0582 - accuracy: 0.9956\nEpoch 5/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0582 - accuracy: 0.9956\nEpoch 6/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0582 - accuracy: 0.9956\nEpoch 7/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0582 - accuracy: 0.9956\nEpoch 8/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0583 - accuracy: 0.9956\nEpoch 9/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0583 - accuracy: 0.9956\nEpoch 10/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0583 - accuracy: 0.9956\nEpoch 11/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0584 - accuracy: 0.9956\nEpoch 12/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0584 - accuracy: 0.9956\nEpoch 13/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0585 - accuracy: 0.9960\nEpoch 14/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0585 - accuracy: 0.9960\nEpoch 15/25\n45/45 [==============================] - 2s 50ms/step - loss: 0.0585 - accuracy: 0.9960\nEpoch 16/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0585 - accuracy: 0.9960\nEpoch 17/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0585 - accuracy: 0.9960\nEpoch 18/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0585 - accuracy: 0.9960\nEpoch 19/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0585 - accuracy: 0.9960\nEpoch 20/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0584 - accuracy: 0.9960\nEpoch 21/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0584 - accuracy: 0.9960\nEpoch 22/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0584 - accuracy: 0.9960\nEpoch 23/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0583 - accuracy: 0.9960\nEpoch 24/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0583 - accuracy: 0.9960\nEpoch 25/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0583 - accuracy: 0.9960\nScore for fold 6: loss of 0.0641767755150795; accuracy of 99.59999918937683%\n------------------------------------------------------------------------\nTraining for fold 7 ...\nEpoch 1/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0653 - accuracy: 0.9956\nEpoch 2/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0653 - accuracy: 0.9956\nEpoch 3/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0652 - accuracy: 0.9956\nEpoch 4/25\n","name":"stdout"},{"output_type":"stream","text":"45/45 [==============================] - 2s 45ms/step - loss: 0.0651 - accuracy: 0.9956\nEpoch 5/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0651 - accuracy: 0.9956\nEpoch 6/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0651 - accuracy: 0.9956\nEpoch 7/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0650 - accuracy: 0.9956\nEpoch 8/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0650 - accuracy: 0.9956\nEpoch 9/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0650 - accuracy: 0.9956\nEpoch 10/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0649 - accuracy: 0.9956\nEpoch 11/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0649 - accuracy: 0.9956\nEpoch 12/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0649 - accuracy: 0.9956\nEpoch 13/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0649 - accuracy: 0.9956\nEpoch 14/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0649 - accuracy: 0.9956\nEpoch 15/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0649 - accuracy: 0.9956\nEpoch 16/25\n45/45 [==============================] - 2s 50ms/step - loss: 0.0649 - accuracy: 0.9956\nEpoch 17/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0649 - accuracy: 0.9956\nEpoch 18/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0649 - accuracy: 0.9956\nEpoch 19/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0649 - accuracy: 0.9956\nEpoch 20/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0649 - accuracy: 0.9956\nEpoch 21/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0649 - accuracy: 0.9956\nEpoch 22/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0626 - accuracy: 0.9956\nEpoch 23/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0622 - accuracy: 0.9956\nEpoch 24/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0620 - accuracy: 0.9956\nEpoch 25/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0620 - accuracy: 0.9956\nScore for fold 7: loss of 0.0; accuracy of 100.0%\n------------------------------------------------------------------------\nTraining for fold 8 ...\nEpoch 1/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0518 - accuracy: 0.9964\nEpoch 2/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0519 - accuracy: 0.9964\nEpoch 3/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0523 - accuracy: 0.9964\nEpoch 4/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0547 - accuracy: 0.9964\nEpoch 5/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0547 - accuracy: 0.9964\nEpoch 6/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 7/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 8/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 9/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 10/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 11/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 12/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 13/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 14/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 15/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 16/25\n45/45 [==============================] - 2s 50ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 17/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 18/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 19/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 20/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 21/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 22/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 23/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 24/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0546 - accuracy: 0.9964\nEpoch 25/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0546 - accuracy: 0.9964\nScore for fold 8: loss of 0.09184684604406357; accuracy of 99.19999837875366%\n------------------------------------------------------------------------\nTraining for fold 9 ...\nEpoch 1/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 2/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 3/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 4/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 5/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 6/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 7/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 8/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 9/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 10/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 11/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 12/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 13/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 14/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 15/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 16/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 17/25\n45/45 [==============================] - 2s 50ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 18/25\n45/45 [==============================] - 2s 53ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 19/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 20/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 21/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 22/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 23/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 24/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0580 - accuracy: 0.9960\nEpoch 25/25\n45/45 [==============================] - 2s 44ms/step - loss: 0.0580 - accuracy: 0.9960\nScore for fold 9: loss of 0.06134837493300438; accuracy of 99.59999918937683%\n------------------------------------------------------------------------\nTraining for fold 10 ...\nEpoch 1/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 2/25\n45/45 [==============================] - 2s 48ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 3/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 4/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 5/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 6/25\n","name":"stdout"},{"output_type":"stream","text":"45/45 [==============================] - 2s 49ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 7/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 8/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 9/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 10/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 11/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 12/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 13/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 14/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 15/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 16/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 17/25\n45/45 [==============================] - 2s 53ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 18/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 19/25\n45/45 [==============================] - 2s 46ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 20/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 21/25\n45/45 [==============================] - 2s 49ms/step - loss: 0.0648 - accuracy: 0.9956\nEpoch 22/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0648 - accuracy: 0.9960\nEpoch 23/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0648 - accuracy: 0.9960\nEpoch 24/25\n45/45 [==============================] - 2s 45ms/step - loss: 0.0648 - accuracy: 0.9960\nEpoch 25/25\n45/45 [==============================] - 2s 47ms/step - loss: 0.0648 - accuracy: 0.9960\nScore for fold 10: loss of 0.0; accuracy of 100.0%\n------------------------------------------------------------------------\nScore per fold\n------------------------------------------------------------------------\n> Fold 1 - Loss: 0.2443392276763916 - Accuracy: 98.7999975681305%\n------------------------------------------------------------------------\n> Fold 2 - Loss: 0.06134837493300438 - Accuracy: 99.59999918937683%\n------------------------------------------------------------------------\n> Fold 3 - Loss: 0.12234532088041306 - Accuracy: 99.19999837875366%\n------------------------------------------------------------------------\n> Fold 4 - Loss: 0.0012238811468705535 - Accuracy: 100.0%\n------------------------------------------------------------------------\n> Fold 5 - Loss: 0.0 - Accuracy: 100.0%\n------------------------------------------------------------------------\n> Fold 6 - Loss: 0.0641767755150795 - Accuracy: 99.59999918937683%\n------------------------------------------------------------------------\n> Fold 7 - Loss: 0.0 - Accuracy: 100.0%\n------------------------------------------------------------------------\n> Fold 8 - Loss: 0.09184684604406357 - Accuracy: 99.19999837875366%\n------------------------------------------------------------------------\n> Fold 9 - Loss: 0.06134837493300438 - Accuracy: 99.59999918937683%\n------------------------------------------------------------------------\n> Fold 10 - Loss: 0.0 - Accuracy: 100.0%\n------------------------------------------------------------------------\nAverage scores for all folds:\n> Accuracy: 99.59999918937683 (+- 0.40000081062316895)\n> Loss: 0.06466288011288271\n------------------------------------------------------------------------\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\naccuracy = history.history['accuracy']\nval_accuracy= history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(accuracy, label='Training Accuracy')\nplt.plot(val_accuracy, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(227, 227),\n    batch_size=2500,\n    class_mode='categorical')\nX,Y = train_generator.next()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# MLP for Pima Indians Dataset with 10-fold cross validation\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.model_selection import KFold\nimport numpy\n# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n\n# split into input (X) and output (Y) variables\n\n# define 10-fold cross validation test harness\nkfold = KFold(n_splits=10, shuffle=True, random_state=seed)\ncvscores = []\nfor train, test in kfold.split(X, Y):\n    \n  # create model\n        model = model\n\n        # Compile model\n        model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n        # Fit the model\n        model.fit(X[train], Y[train], epochs=25, batch_size=50, verbose=1)\n        # evaluate the model\n        scores = model.evaluate(X[test], Y[test], verbose=0)\n        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n        cvscores.append(scores[1] * 100)\nprint(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}